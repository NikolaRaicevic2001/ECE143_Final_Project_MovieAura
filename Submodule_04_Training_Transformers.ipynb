{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2890,
     "status": "ok",
     "timestamp": 1732248014584,
     "user": {
      "displayName": "Nikola Raicevic",
      "userId": "00295493370424344016"
     },
     "user_tz": 480
    },
    "id": "j3CU1s0RA9Wv"
   },
   "outputs": [],
   "source": [
    "from submodule_04_Constants import (SEQ_LEN,EMBEDDING_DIM,BATCH_SIZE,NUM_LAYERS,NUM_HEADS,LEARNING_RATE,DROPOUT_RATE,EPOCHS,INPUT_DIM,NUM_MOVIES,DEVICE)\n",
    "from submodule_04 import TransformerRecModel, train_model, evaluate_model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape (X): (14010, 1707)\n",
      "Labels shape   (y): (14010,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the preprocessed data embeddings\n",
    "movie_embeddings = pd.read_pickle(\"Dataset_Processed/Movie_Embeddings.pkl\")\n",
    "\n",
    "# Extract features for training\n",
    "features = np.array(list(movie_embeddings['Description_Embedding']))    # Description embeddings\n",
    "keywords = np.array(list(movie_embeddings['Keyword_Embedding']))        # Keyword embeddings\n",
    "genres = movie_embeddings.loc[:, \"Action\":\"Western\"].values             # Genre embeddings\n",
    "countries = movie_embeddings.loc[:, \"Afghanistan\":\"Zimbabwe\"].values    # Country embeddings\n",
    "other_features = movie_embeddings[[\"Adult\",\"Normalized_Release_Year\",\"Normalized_Rating\",\"Normalized_Popularity\"]].values\n",
    "\n",
    "# Training Features\n",
    "X = np.hstack((features, keywords, genres, countries, other_features)) \n",
    "# Training Labels\n",
    "y = movie_embeddings['ID'].values \n",
    "\n",
    "print(f\"Features shape (X): {X.shape}\") \n",
    "print(f\"Labels shape   (y): {y.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sequences shape: (13990, 20, 1707)\n",
      "y_sequences shape: (13990,)\n"
     ]
    }
   ],
   "source": [
    "# Create a function to reshape features into sequences\n",
    "def create_sequences(X, y, seq_len):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through the data and create sequences\n",
    "    for i in range(len(X) - seq_len):\n",
    "        sequences.append(X[i:i + seq_len])  # Get the next SEQ_LEN samples\n",
    "        labels.append(y[i + seq_len])       # Label for the last sample in the sequence\n",
    "    \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Generate sequences from the original features and labels\n",
    "X_sequences, y_sequences = create_sequences(X, y, SEQ_LEN)\n",
    "\n",
    "# Check shapes\n",
    "print(\"X_sequences shape:\", X_sequences.shape)  # Should be (num_samples - SEQ_LEN, SEQ_LEN, INPUT_DIM)\n",
    "print(\"y_sequences shape:\", y_sequences.shape)  # Should be (num_samples - SEQ_LEN,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Data Shape: torch.Size([11192, 20, 1707])\n",
      "Final Training Labels Shape: torch.Size([11192])\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Dataset and Dataloader\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Check final shapes\n",
    "print(\"Final Training Data Shape:\", X_train_tensor.shape)  # Should be (num_samples - SEQ_LEN, SEQ_LEN, INPUT_DIM)\n",
    "print(\"Final Training Labels Shape:\", y_train_tensor.shape)  # Should be (num_samples - SEQ_LEN,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQ_LEN: 20, EMBEDDING_DIM: 128, BATCH_SIZE: 32, NUM_LAYERS: 2, NUM_HEADS: 4, LEARNING_RATE: 0.001, DROPOUT_RATE: 0.2, EPOCHS: 20, INPUT_DIM: 1707, NUM_MOVIES: 14010\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"SEQ_LEN: {SEQ_LEN}, EMBEDDING_DIM: {EMBEDDING_DIM}, BATCH_SIZE: {BATCH_SIZE}, NUM_LAYERS: {NUM_LAYERS}, NUM_HEADS: {NUM_HEADS}, LEARNING_RATE: {LEARNING_RATE}, DROPOUT_RATE: {DROPOUT_RATE}, EPOCHS: {EPOCHS}, INPUT_DIM: {INPUT_DIM}, NUM_MOVIES: {NUM_MOVIES}\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KIbCiXTDDgL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 9.5475\n",
      "Epoch 2/20, Loss: 9.5475\n",
      "Epoch 3/20, Loss: 9.5475\n",
      "Epoch 4/20, Loss: 9.5475\n",
      "Epoch 5/20, Loss: 9.5475\n",
      "Validation Loss: 9.5476, Accuracy: 0.0000, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 6/20, Loss: 9.5475\n",
      "Epoch 7/20, Loss: 9.5475\n",
      "Epoch 8/20, Loss: 9.5475\n",
      "Epoch 9/20, Loss: 9.5475\n",
      "Epoch 10/20, Loss: 9.5475\n",
      "Validation Loss: 9.5476, Accuracy: 0.0000, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 11/20, Loss: 9.5475\n",
      "Epoch 12/20, Loss: 9.5475\n",
      "Epoch 13/20, Loss: 9.5475\n",
      "Epoch 14/20, Loss: 9.5475\n",
      "Epoch 15/20, Loss: 9.5475\n",
      "Validation Loss: 9.5476, Accuracy: 0.0000, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 16/20, Loss: 9.5475\n",
      "Epoch 17/20, Loss: 9.5475\n",
      "Epoch 18/20, Loss: 9.5475\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model, Optimizer, and Loss Function\n",
    "model = TransformerRecModel(num_movies=NUM_MOVIES, input_dim=INPUT_DIM, sequence_len=SEQ_LEN, embedding_dim=EMBEDDING_DIM, num_heads=NUM_HEADS, num_layers=NUM_LAYERS, dropout_rate=DROPOUT_RATE)\n",
    "model.to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Lists to store loss values for plotting\n",
    "train_losses = []\n",
    "average_losses = []\n",
    "accuracy_values = []\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "f1_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion, DEVICE)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {train_loss:.4f}\")\n",
    "\n",
    "    avg_loss, accuracy, precision, recall, f1 = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "    average_losses.append(avg_loss)\n",
    "    accuracy_values.append(accuracy)\n",
    "    precision_values.append(precision)\n",
    "    recall_values.append(recall)\n",
    "    f1_values.append(f1)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    if (epoch + 1) % 5 == 0:  \n",
    "        print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'NN_Models/TransformerRecModel_{}.pth'.format(EPOCHS))\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, EPOCHS + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('NN_Models/Training_Loss_{}.png'.format(EPOCHS))\n",
    "plt.show()\n",
    "\n",
    "# Plotting the training loss with a log scale\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.semilogy(range(1, EPOCHS + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.title('Training Loss over Epochs (Log Scale)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('NN_Models/Training_Loss_Log_{}.png'.format(EPOCHS))\n",
    "plt.show()\n",
    "\n",
    "# Plotting the evaluation metrics\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, EPOCHS + 1), accuracy_values, label='Accuracy')\n",
    "plt.plot(range(1, EPOCHS + 1), precision_values, label='Precision')\n",
    "plt.plot(range(1, EPOCHS + 1), recall_values, label='Recall')\n",
    "plt.plot(range(1, EPOCHS + 1), f1_values, label='F1 Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Evaluation Metrics over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('NN_Models/Evaluation_Metrics_{}.png'.format(EPOCHS))\n",
    "plt.show()\n",
    "\n",
    "# Plotting Loss and Metrics\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1) # Plot Training Loss\n",
    "plt.plot(range(1, EPOCHS + 1), train_losses, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2) # Plot Validation Loss\n",
    "plt.plot(range(1, len(average_losses) + 1), average_losses, label='Validation Loss', color='orange')\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3) # Plot Accuracy\n",
    "plt.plot(range(1, len(accuracy_values) + 1), accuracy_values, label='Accuracy', color='green')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4) # Plot F1 Score\n",
    "plt.plot(range(1, len(f1_values) + 1), f1_values, label='F1 Score', color='red')\n",
    "plt.title('F1 Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('NN_Models/Evaluation_{}.png'.format(EPOCHS))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOZMJ5Dj5IrHXqIBvf8u51Y",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
